{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations # To prevent Subscript for class \"list\" will generate runtime exception; enclose type annotation in quotes\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import scipy\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from Kmeans import *\n",
    "import math\n",
    "%matplotlib inline\n",
    "# pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ml-1m/users.dat', delimiter='::', names=['UserID','Gender','Age','Occupation','Zip-code'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "df['Gender']=le.fit_transform(df['Gender'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Zip-code'] = df['Zip-code'].apply(lambda x: int(x.split('-')[0]) if type(x)==str else x)\n",
    "df['Zip-code'] = df['Zip-code'].apply(lambda x: int(str(x)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Zip-code'] = df['Zip-code'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode=df['Zip-code']\n",
    "df = pd.get_dummies(\n",
    "    data=df, # dataframe to one hot encode\n",
    "    columns=[\"Zip-code\"])\n",
    "df = pd.get_dummies(\n",
    "    data=df, # dataframe to one hot encode\n",
    "    columns=[\"Occupation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['UserID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns[2:]:\n",
    "\tlst=[]\n",
    "\tfor j in df[i]:\n",
    "\t\tif(j):\n",
    "\t\t\tlst.append(1)\n",
    "\t\telse:\n",
    "\t\t\tlst.append(0)\n",
    "\tdf[i]=lst\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].apply(lambda x: x/56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=pd.read_csv('ml-1m/ratings.dat', delimiter='::', names=['UserID','MovieID','Rating','TimeStamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=ratings.loc[:, 'Rating'].mean()\n",
    "std=ratings.loc[:, 'Rating'].std()\n",
    "rating = ratings['Rating'].apply(lambda x: (x-mean)/ std)\n",
    "min=ratings.loc[:, 'Rating'].min()\n",
    "max=ratings.loc[:, 'Rating'].max()\n",
    "rating = ratings['Rating'].apply(lambda x: (x-min)/ (max-min))\n",
    "ratings['Rating']=rating\n",
    "# min=ratings.loc[:, 'TimeStamp'].min()\n",
    "# ratings['TimeStamp'] = ratings['TimeStamp'].apply(lambda x: x-min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.sort_values(by=['TimeStamp'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=list(ratings['TimeStamp'])\n",
    "plt.plot(range(len(tmp)),tmp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=pd.read_csv('ml-1m/movies.dat', delimiter='::', names=[\"Title\",\"Genres\"],  encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['Genres'] = movies['Genres'].apply(lambda x: x.split(\"|\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genres=[\"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"]\n",
    "tmp=[[] for _ in range(6040)]\n",
    "for i in Genres:\n",
    "    df[i]=tmp\n",
    "df['LastLog']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_rows = 4000\n",
    "for j in ratings.index:\n",
    "    uid,mid,rating,time=ratings.iloc[j]\n",
    "    uid=int(uid)\n",
    "    mid=int(mid)\n",
    "    time=int(time)\n",
    "    try:\n",
    "        genres=movies.at[mid-1,\"Genres\"]\n",
    "        for i in genres:\n",
    "            temp = df.iloc[uid-1][i]\n",
    "            if(len(temp)==0 or time-temp[1]>=31536000):\n",
    "                temp=[rating,time]\n",
    "            else:\n",
    "                temp=[rating+temp[0]*(1-(time-temp[1])/31536000),time]\n",
    "            df.at[uid-1,i]=temp\n",
    "            df.at[uid-1,\"LastLog\"]=time\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_off=df.copy()\n",
    "for i in Genres:\n",
    "    for j in df_off.index:\n",
    "        temp=df_off.at[j,i]\n",
    "        try:\n",
    "            if(df_off.at[j,\"LastLog\"]<=31536000):\n",
    "                df_off.at[j,i]=temp[0]*(temp[1]/df_off.at[j,\"LastLog\"])\n",
    "            else:\n",
    "                if(df_off.at[j,\"LastLog\"]-temp[1]>=31536000):\n",
    "                    df_off.at[j,i]=0\n",
    "                else:\n",
    "                    df_off.at[j,i]=temp[0]*(1-(df_off.at[j,\"LastLog\"]-temp[1])/31536000)\n",
    "        except:\n",
    "            df_off.at[j,i]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_off.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_off.drop([\"LastLog\"],axis=1,inplace=True)\n",
    "df_off['Zip-code']=zipcode\n",
    "grouped = df_off.groupby(['Age','Gender','Zip-code'])\n",
    "grouped.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Genres:\n",
    "    df_off[i] = grouped[i].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_off.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_off.drop(\"Zip-code\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToNormalize=df_off[Genres]\n",
    "min=ToNormalize.min(axis=1)\n",
    "max=ToNormalize.max(axis=1)\n",
    "# print(min,max)\n",
    "for i in ToNormalize.index:\n",
    "    for j in Genres:\n",
    "        ToNormalize.at[i,j]=(ToNormalize.at[i,j]-min[i])/(max[i]-min[i])\n",
    "# ToNormalize=ToNormalize.apply(lambda x:(x-min)/max, axis=1)\n",
    "for i in Genres:\n",
    "    df_off[i]=ToNormalize[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_off.to_csv('preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SVD import *\n",
    "u,s,sigma,V_trans = ReducedSVD(df.to_numpy(),0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,s,sigma,V_trans = ReducedSVD(df.to_numpy(),0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cluster = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(u@sigma@V_trans,columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_to_matrix(X_train,y_train,num_cluster):\n",
    "    k=Kmeans(K=num_cluster,iter=150,p=2,random_state=random_state)\n",
    "    y_pred,_=k.predict(np.array(X_train),choice=0)\n",
    "    k.centroids=np.array(k.centroids)\n",
    "    empty_cluster = []\n",
    "    for idx,i in enumerate(k.clusters):\n",
    "        if len(i)==0:\n",
    "            empty_cluster.append(idx)\n",
    "    X_train2 = pd.concat([X_train,y_train,pd.DataFrame(y_pred,columns=[\"label\"],dtype='int')],axis=\"columns\")\n",
    "    df_cluster_rep = X_train2.groupby(['label'], as_index=False).mean()\n",
    "    df_cluster_rep.drop(labels=\"label\",axis=\"columns\",inplace=True)\n",
    "    matrix = df_cluster_rep.to_numpy()\n",
    "    final_matrix = []\n",
    "    j = 0\n",
    "    for i in range(num_cluster):\n",
    "        if i in empty_cluster:\n",
    "            final_matrix.append(np.zeros(25))\n",
    "        else:\n",
    "            final_matrix.append(matrix[j])\n",
    "            j+=1\n",
    "\n",
    "    return np.array(final_matrix),k\n",
    "    return matrix,k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[df.columns[0],df.columns[1],df.columns[2],df.columns[3],df.columns[4]]]\n",
    "y = df.drop(labels=[\"Data Structures and Algorithms\",\"Computer Architecture\\n\",\"Discrete Mathematics\\n\",\"Economics\",\"Programming-2\"],axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.05, shuffle=True,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix,kmeans_model = cluster_to_matrix(X_train,y_train,num_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(datapoint,kmeans,matrix_clean):\n",
    "    '''\n",
    "        @input: Takes in a datapoint, kmeans object, and information matrix\n",
    "        @output: Returns: rating sorted with index for column name mapping\n",
    "    '''\n",
    "    y_pred = kmeans.predictPoint(datapoint)\n",
    "    inferred_full = matrix_clean[y_pred]\n",
    "    inferred = inferred_full[5:]\n",
    "    sorted_ratings = []\n",
    "    for idx,element in enumerate(inferred):\n",
    "        sorted_ratings.append([element,idx+5])\n",
    "    sorted_ratings.sort()\n",
    "    sorted_ratings.reverse()\n",
    "    return sorted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_numpy()[0][:5]\n",
    "sorted_ratings = predict(X_test.to_numpy()[0][:5],kmeans_model,matrix)\n",
    "s=\"Top 5 PREDICTED recommended electives are:\\n\"\n",
    "for i in range(5):\n",
    "    s+=df.columns[sorted_ratings[i][1]]+\"\\n\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred = y_test.to_numpy()[0]\n",
    "for idx,element in enumerate(inferred):\n",
    "    sorted_ratings.append([element,idx+5])\n",
    "sorted_ratings.sort()\n",
    "sorted_ratings.reverse()\n",
    "s=\"Top 5 ACTUAL recommended electives are:\\n\"\n",
    "for i in range(5):\n",
    "    s+=df.columns[sorted_ratings[i][1]]+\"\\n\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_dataset(X_test,kmeans_instance,matrix_clean):\n",
    "    ''' Runs out inference and return predicted ratings of subjects\n",
    "        @input: X_test,kmeans object, clean_matrix after SVD\n",
    "    '''\n",
    "    X_test = X_test.to_numpy()\n",
    "    y_pred = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        datapoint =X_test[i][:5]\n",
    "        y_pred.append(predict(datapoint,kmeans_instance,matrix_clean))\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_for_dataset(X_test,kmeans_model,matrix)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred,y_test):\n",
    "    ''' Finds out % common subject in top 5 rated subjects (predicted and actual)\n",
    "        @input: predicted values and test dataset values\n",
    "        @output: accuracy value\n",
    "    '''\n",
    "    y_test = y_test.to_numpy()\n",
    "    sorted_ratings_actual = []\n",
    "    for i in range(y_test.shape[0]):\n",
    "        inferred = y_test[i]\n",
    "        t = []\n",
    "        for idx,element in enumerate(inferred):\n",
    "            t.append([element,idx+5])\n",
    "        t.sort()\n",
    "        t.reverse()\n",
    "        sorted_ratings_actual.append(np.array(t))\n",
    "    sorted_ratings_actual = np.array(sorted_ratings_actual)\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "\n",
    "    for i in range(len(sorted_ratings_actual)):\n",
    "        total+=5\n",
    "        temp = sorted_ratings_actual[i][:5]\n",
    "        # if i ==1:\n",
    "        #     print(temp)\n",
    "        for j in range(5):\n",
    "            for k in range(len(temp)):\n",
    "                if(y_pred[i][j][1]==temp[k][1]):correct+=1\n",
    "\n",
    "    perecent_correct_for_datapoint = []\n",
    "\n",
    "    for i in range(len(sorted_ratings_actual)):\n",
    "        per_correct = 0\n",
    "        temp = sorted_ratings_actual[i][:5]\n",
    "        # if i ==1:\n",
    "        #     print(temp)\n",
    "        for j in range(5):\n",
    "            for k in range(len(temp)):\n",
    "                if(y_pred[i][j][1]==temp[k][1]):per_correct+=1\n",
    "        perecent_correct_for_datapoint.append(per_correct/5)\n",
    "    # print(\"Total Entries received: \", len(sorted_ratings_actual)*5,\" Total Correct: \",correct)\n",
    "    return 100*(correct/total),perecent_correct_for_datapoint,sorted_ratings_actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_val,per_point_val,y_sorted_actual = accuracy(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_point_val"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SVD import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "accuracy_list_gs = []\n",
    "def grid_search(df):\n",
    "    for i in range(4,9):\n",
    "        for j in range(0,i):\n",
    "            # print(i,j)\n",
    "            u,s,sigma,V_trans = ReducedSVD(df.to_numpy(),0,j)\n",
    "            df = pd.DataFrame(u@sigma@V_trans,columns=df.columns)\n",
    "            X = df[[df.columns[0],df.columns[1],df.columns[2],df.columns[3],df.columns[4]]]\n",
    "            y = df.drop(labels=[\"Data Structures and Algorithms\",\"Computer Architecture\\n\",\"Discrete Mathematics\\n\",\"Economics\",\"Programming-2\"],axis=\"columns\")\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.05, shuffle=True,random_state=random_state)\n",
    "            matrix,kmeans_model = cluster_to_matrix(X_train,y_train,i)\n",
    "            if(matrix.shape[0]<i):\n",
    "                break\n",
    "            y_pred = predict_for_dataset(X_train,kmeans_model,matrix)\n",
    "            overall_val,per_point_val,y_sorted_actual = accuracy(y_pred,y_train)\n",
    "            accuracy_list_gs.append([overall_val,('Number of cluster',i),('SV removed',j)])\n",
    "    accuracy_list_gs.sort(reverse=True)\n",
    "grid_search(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6\n",
    "to_remove = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
